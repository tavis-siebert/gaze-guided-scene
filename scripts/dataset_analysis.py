#!/usr/bin/env python3
"""
Analysis and visualization helper for dataset generated by dataset_to_csv.py.
Creates various distribution plots and statistics for the dataset.
"""

import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from typing import Dict, List, Tuple, Any
from collections import Counter, defaultdict

def load_mapping(file_path: str) -> Dict[int, str]:
    """Load index to name mapping from file."""
    mapping = {}
    with open(file_path, 'r') as f:
        for line in f:
            line = line.strip()
            if not line:
                continue
                
            # Extract name and index from line
            parts = line.rsplit(' ', 1)
            if len(parts) == 2:
                name, idx_str = parts
                try:
                    idx = int(idx_str)
                    mapping[idx] = name
                except ValueError:
                    print(f"Warning: Invalid line format in {file_path}: {line}")
    return mapping

def collect_noun_distribution(df: pd.DataFrame, noun_mapping: Dict[int, str]) -> Dict[str, Counter]:
    """
    Collect distribution of nouns across splits.
    
    Args:
        df: DataFrame with dataset information
        noun_mapping: Mapping from noun indices to names
        
    Returns:
        Dictionary mapping split names to Counter objects
    """
    distribution = defaultdict(Counter)
    
    for _, row in df.iterrows():
        split = row['split']
        
        # Parse noun indices
        if pd.notna(row['node_noun_indices']) and row['node_noun_indices']:
            noun_indices = [int(idx) for idx in row['node_noun_indices'].split(',')]
            
            # Count each noun
            for idx in noun_indices:
                noun_name = noun_mapping.get(idx, f"Unknown-{idx}")
                distribution[split][noun_name] += 1
    
    return distribution

def collect_action_distribution(df: pd.DataFrame, action_mapping: Dict[int, str]) -> Dict[str, Counter]:
    """
    Collect distribution of actions across splits.
    
    Args:
        df: DataFrame with dataset information
        action_mapping: Mapping from action indices to names
        
    Returns:
        Dictionary mapping split names to Counter objects
    """
    distribution = defaultdict(Counter)
    
    for _, row in df.iterrows():
        split = row['split']
        
        # Count next action
        if pd.notna(row['next_action_id']):
            action_id = int(row['next_action_id'])
            action_name = action_mapping.get(action_id, f"Unknown-{action_id}")
            distribution[split][action_name] += 1
        
        # Count future actions
        if pd.notna(row['future_actions']) and row['future_actions']:
            action_indices = [int(idx) for idx in row['future_actions'].split(',')]
            
            for idx in action_indices:
                action_name = action_mapping.get(idx, f"Unknown-{idx}")
                distribution[split][action_name] += 1
    
    return distribution

def plot_distribution(data: Dict[str, Counter], title: str, output_path: str, 
                      top_n: int = 15, figsize: Tuple[int, int] = (12, 10)):
    """
    Plot distribution of categories.
    
    Args:
        data: Dictionary mapping split names to Counter objects
        title: Plot title
        output_path: Path to save the plot
        top_n: Number of top categories to show
        figsize: Figure size
    """
    plt.figure(figsize=figsize)
    
    num_splits = len(data)
    for i, (split_name, counter) in enumerate(data.items()):
        # Get the top N most common items
        top_items = counter.most_common(top_n)
        labels, values = zip(*top_items) if top_items else ([], [])
        
        # Create subplot for each split
        plt.subplot(num_splits, 1, i+1)
        
        # Create horizontal bar chart
        y_pos = np.arange(len(labels))
        plt.barh(y_pos, values, color=f"C{i}")
        plt.yticks(y_pos, labels)
        plt.title(f"{split_name.capitalize()} Split")
        plt.xlabel("Count")
    
    plt.suptitle(title, fontsize=16)
    plt.tight_layout(rect=[0, 0, 1, 0.95])  # Make room for the suptitle
    plt.savefig(output_path, bbox_inches='tight')
    plt.close()
    print(f"Saved distribution plot to {output_path}")

def plot_edge_node_distribution(df: pd.DataFrame, output_path: str):
    """
    Plot distribution of nodes and edges per graph.
    
    Args:
        df: DataFrame with dataset information
        output_path: Path to save the plot
    """
    plt.figure(figsize=(15, 10))
    
    # Group data by split
    train_df = df[df['split'] == 'train']
    val_df = df[df['split'] == 'val']
    
    # Plot node distribution
    plt.subplot(2, 2, 1)
    sns.histplot(train_df['num_nodes'], kde=True, color="blue", label="Train")
    plt.title("Node Distribution (Train)")
    plt.xlabel("Number of Nodes")
    plt.ylabel("Frequency")
    
    plt.subplot(2, 2, 2)
    sns.histplot(val_df['num_nodes'], kde=True, color="orange", label="Val")
    plt.title("Node Distribution (Val)")
    plt.xlabel("Number of Nodes")
    plt.ylabel("Frequency")
    
    # Plot edge distribution
    plt.subplot(2, 2, 3)
    sns.histplot(train_df['num_edges'], kde=True, color="blue", label="Train")
    plt.title("Edge Distribution (Train)")
    plt.xlabel("Number of Edges")
    plt.ylabel("Frequency")
    
    plt.subplot(2, 2, 4)
    sns.histplot(val_df['num_edges'], kde=True, color="orange", label="Val")
    plt.title("Edge Distribution (Val)")
    plt.xlabel("Number of Edges")
    plt.ylabel("Frequency")
    
    plt.tight_layout()
    plt.savefig(output_path, bbox_inches='tight')
    plt.close()
    print(f"Saved edge-node distribution plot to {output_path}")

def plot_edge_to_node_ratio(df: pd.DataFrame, output_path: str):
    """
    Plot distribution of edge-to-node ratio.
    
    Args:
        df: DataFrame with dataset information
        output_path: Path to save the plot
    """
    plt.figure(figsize=(12, 6))
    
    # Calculate edge-to-node ratios
    df['edge_to_node_ratio'] = df['num_edges'] / df['num_nodes'].replace(0, 1)  # Avoid division by zero
    
    # Plot density plot for each split
    for i, split in enumerate(['train', 'val']):
        split_df = df[df['split'] == split]
        if not split_df.empty:
            sns.kdeplot(split_df['edge_to_node_ratio'], label=split.capitalize(), 
                       fill=True, color=f"C{i}")
    
    plt.title("Edge-to-Node Ratio Distribution")
    plt.xlabel("Edge-to-Node Ratio")
    plt.ylabel("Density")
    plt.legend()
    plt.grid(alpha=0.3)
    plt.tight_layout()
    plt.savefig(output_path, bbox_inches='tight')
    plt.close()
    print(f"Saved edge-to-node ratio plot to {output_path}")

def plot_bidirectional_stats(df: pd.DataFrame, output_path: str):
    """
    Plot statistics about bidirectional edges.
    
    Args:
        df: DataFrame with dataset information
        output_path: Path to save the plot
    """
    plt.figure(figsize=(10, 6))
    
    # Count bidirectional graphs by split
    bidirectional_counts = df.groupby(['split', 'bidirectional']).size().unstack(fill_value=0)
    
    # Create bar plot
    bidirectional_counts.plot(kind='bar', stacked=True)
    plt.title("Bidirectional Edge Statistics")
    plt.xlabel("Split")
    plt.ylabel("Count")
    plt.xticks(rotation=0)
    plt.legend(title="Has Bidirectional Edges")
    plt.grid(axis='y', alpha=0.3)
    plt.tight_layout()
    plt.savefig(output_path, bbox_inches='tight')
    plt.close()
    print(f"Saved bidirectional stats plot to {output_path}")

def plot_future_actions_count(df: pd.DataFrame, output_path: str):
    """
    Plot distribution of future action counts.
    
    Args:
        df: DataFrame with dataset information
        output_path: Path to save the plot
    """
    plt.figure(figsize=(12, 6))
    
    # Count number of future actions per graph
    df['future_action_count'] = df['future_actions'].apply(
        lambda x: len(x.split(',')) if pd.notna(x) and x else 0
    )
    
    # Plot for each split
    for i, split in enumerate(['train', 'val']):
        split_df = df[df['split'] == split]
        if not split_df.empty:
            plt.subplot(1, 2, i+1)
            sns.histplot(split_df['future_action_count'], discrete=True, 
                        kde=False, color=f"C{i}")
            plt.title(f"Future Actions Count ({split.capitalize()})")
            plt.xlabel("Number of Future Actions")
            plt.ylabel("Frequency")
    
    plt.tight_layout()
    plt.savefig(output_path, bbox_inches='tight')
    plt.close()
    print(f"Saved future actions count plot to {output_path}")

def analyze_dataset(df: pd.DataFrame, noun_mapping_path: str, action_mapping_path: str, output_dir: str):
    """
    Analyze dataset and generate visualizations.
    
    Args:
        df: DataFrame with dataset information
        noun_mapping_path: Path to noun mapping file
        action_mapping_path: Path to action mapping file
        output_dir: Directory to save analysis results
    """
    print(f"Starting dataset analysis...")
    
    # Ensure output directory exists
    os.makedirs(output_dir, exist_ok=True)
    
    # Load mappings
    noun_mapping = load_mapping(noun_mapping_path)
    action_mapping = load_mapping(action_mapping_path)
    
    # Collect distributions
    noun_distribution = collect_noun_distribution(df, noun_mapping)
    action_distribution = collect_action_distribution(df, action_mapping)
    
    # Generate plots
    plot_distribution(
        noun_distribution, 
        "Noun Distribution in Graphs",
        os.path.join(output_dir, "noun_distribution.png")
    )
    
    plot_distribution(
        action_distribution, 
        "Action Distribution in Graphs",
        os.path.join(output_dir, "action_distribution.png"),
        top_n=20
    )
    
    plot_edge_node_distribution(
        df,
        os.path.join(output_dir, "node_edge_distribution.png")
    )
    
    plot_edge_to_node_ratio(
        df,
        os.path.join(output_dir, "edge_node_ratio.png")
    )
    
    plot_bidirectional_stats(
        df,
        os.path.join(output_dir, "bidirectional_stats.png")
    )
    
    plot_future_actions_count(
        df,
        os.path.join(output_dir, "future_actions_count.png")
    )
    
    # Generate summary statistics
    with open(os.path.join(output_dir, "summary_stats.txt"), "w") as f:
        f.write("Dataset Summary Statistics\n")
        f.write("========================\n\n")
        
        # Overall stats
        f.write(f"Total Graphs: {len(df)}\n")
        f.write(f"Train Split: {len(df[df['split'] == 'train'])}\n")
        f.write(f"Val Split: {len(df[df['split'] == 'val'])}\n\n")
        
        # Node stats
        f.write("Node Statistics:\n")
        f.write(f"  Avg Nodes per Graph: {df['num_nodes'].mean():.2f}\n")
        f.write(f"  Min Nodes: {df['num_nodes'].min()}\n")
        f.write(f"  Max Nodes: {df['num_nodes'].max()}\n\n")
        
        # Edge stats
        f.write("Edge Statistics:\n")
        f.write(f"  Avg Edges per Graph: {df['num_edges'].mean():.2f}\n")
        f.write(f"  Min Edges: {df['num_edges'].min()}\n")
        f.write(f"  Max Edges: {df['num_edges'].max()}\n\n")
        
        # Bidirectional stats
        f.write("Bidirectional Edge Statistics:\n")
        f.write(f"  Graphs with all bidirectional edges: {df['bidirectional'].sum()}\n")
        f.write(f"  Graphs with some non-bidirectional edges: {len(df) - df['bidirectional'].sum()}\n\n")
        
        # Top nouns and actions
        f.write("Top 10 Nouns:\n")
        all_nouns = Counter()
        for counter in noun_distribution.values():
            all_nouns.update(counter)
        for noun, count in all_nouns.most_common(10):
            f.write(f"  {noun}: {count}\n")
        
        f.write("\nTop 10 Actions:\n")
        all_actions = Counter()
        for counter in action_distribution.values():
            all_actions.update(counter)
        for action, count in all_actions.most_common(10):
            f.write(f"  {action}: {count}\n")
    
    print(f"All analysis results saved to {output_dir}")

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description='Analyze dataset CSV and generate visualizations')
    parser.add_argument('csv_path', help='Path to the dataset CSV file')
    parser.add_argument('-o', '--output-dir', help='Output directory for analysis results')
    parser.add_argument('--noun-mapping', help='Path to noun_idx.txt (default: egtea_gaze/action_annotation/noun_idx.txt)')
    parser.add_argument('--action-mapping', help='Path to action_idx.txt (default: egtea_gaze/action_annotation/action_idx.txt)')
    
    args = parser.parse_args()
    
    # Set defaults
    output_dir = args.output_dir or os.path.join(os.path.dirname(args.csv_path), "analysis")
    noun_mapping = args.noun_mapping or "egtea_gaze/action_annotation/noun_idx.txt"
    action_mapping = args.action_mapping or "egtea_gaze/action_annotation/action_idx.txt"
    
    # Load CSV
    df = pd.read_csv(args.csv_path)
    
    # Run analysis
    analyze_dataset(df, noun_mapping, action_mapping, output_dir) 